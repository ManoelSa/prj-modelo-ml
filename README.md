# ü¶ü Predi√ß√£o de Gravidade da Dengue

## üéØ Objetivo
A dengue √© uma doen√ßa que pode evoluir para **quadros graves**, exigindo aten√ß√£o r√°pida no diagn√≥stico e tratamento.
Tamb√©m conhecida como dengue com sinais de alarme, a dengue grave √© aquela que ocorre quando, de tr√™s a sete dias ap√≥s o in√≠cio dos sintomas tradicionais, o paciente entra em uma fase cr√≠tica, apresentando piora no estado cl√≠nico geral. A doen√ßa progride, geralmente, para sintomas graves e pode inclusive levar a √≥bito.  
O objetivo desta classifica√ß√£o √© **prever a gravidade da doen√ßa** a partir de dados cl√≠nicos, demogr√°ficos e epidemiol√≥gicos, permitindo:  
- **Apoiar profissionais de sa√∫de** na tomada de decis√£o.  
- **Agilizar o tratamento** de pacientes com maior risco.  
- **Auxiliar na gest√£o hospitalar**, prevenindo sobrecarga e melhorando o planejamento de recursos.

## üåü Vis√£o Geral
Este projeto aplica t√©cnicas de **aprendizado supervisionado** para treinar modelos que estimam a probabilidade de um caso de dengue evoluir para forma grave.  
O modelo final foi integrado em uma aplica√ß√£o **Streamlit**, oferecendo uma interface simples para previs√£o em tempo real.

## ‚ú® Principais Funcionalidades

- üîé An√°lise explorat√≥ria e limpeza dos dados.  
- üß† Treinamento e compara√ß√£o entre diferentes algoritmos de classifica√ß√£o.  
- üìà Avalia√ß√£o de m√©tricas como *Recall*, *Precision*, *ROC AUC* e *Matriz de Confus√£o*.  
- üíæ Salvamento e carregamento de modelos com **joblib**.  
- üåê Aplica√ß√£o **Streamlit** para previs√£o de gravidade com inser√ß√£o de dados de pacientes. 

## üõ†Ô∏è Detalhes de Implementa√ß√£o

- **Linguagem:** Python 3.12.6  
- **Bibliotecas principais:**  
  - pandas, numpy, os  
  - scikit-learn (LogisticRegression, DecisionTreeClassifier, GridSearchCV, m√©tricas)  
  - xgboost  
  - matplotlib  
  - joblib  
  - streamlit  

- **Modelos utilizados nos testes:**  
  - LogisticRegression  
  - DecisionTreeClassifier 
  - XGBClassifier 

## üóÇÔ∏è Estrutura do Projeto
```text
prj-modelo-ml/
‚îú‚îÄ‚îÄ dataset/ # Conjunto de dados em formato parquet
‚îÇ ‚îî‚îÄ‚îÄ DENGBR25.parquet
‚îú‚îÄ‚îÄ models/ # Modelos treinados
‚îÇ ‚îî‚îÄ‚îÄ xgb_model.pkl
‚îú‚îÄ‚îÄ notebook/ # Notebooks de experimenta√ß√£o e an√°lises
‚îÇ ‚îî‚îÄ‚îÄ EDA.ipynb
| ‚îî‚îÄ‚îÄ modelo.ipynb
‚îú‚îÄ‚îÄ src/ # (aplica√ß√£o em Streamlit)
‚îÇ ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ .gitignore # Arquivos ignorados no versionamento
‚îú‚îÄ‚îÄ README.md # Documenta√ß√£o do projeto
‚îî‚îÄ‚îÄ requirements.txt # Depend√™ncias do projeto 

```

## üîÄ Fluxo de Uso

```text
[Usu√°rio] --(input de dados cl√≠nicos)--> Streamlit 
            |
            v
     [Modelo carregado com joblib]
            |
            v
   [Previs√£o de gravidade do caso]
            |
            v
[Interface] Exibe resultado e m√©tricas associadas

```

## üíª Exemplos de uso Localmente
```bash
# 1. Clone o reposit√≥rio
git https://github.com/ManoelSa/prj-modelo-ml.git
cd prj-modelo-ml

# 2. (Opcional) Crie e ative um ambiente virtual
python -m venv venv
venv\Scripts\activate #Linux: source venv/bin/activate

# 3. Instale as depend√™ncias
pip install -r requirements.txt

# 4. Modelo pr√©-treinado j√° dispon√≠vel
# O arquivo models/xgb_model.pkl j√° pode ser usado pela aplica√ß√£o

# 5. (Opcional) Treinar novamente o modelo
# Abra e execute o notebook em: notebook/modelo.ipynb
# Obs.: A etapa de "Tuning hiperparam - Conferindo melhores modelos" leva em m√©dia uns 20 min para execu√ß√£o.

# 6. Execute a aplica√ß√£o Streamlit
cd src
streamlit run app.py

# 7. Url de Acesso
http://localhost:8501

```

## üèÜ Escolha do Modelo Final

Foram testados tr√™s algoritmos principais, comparados pelas m√©tricas mais relevantes para o problema (foco na **classe 1 ‚Äì casos graves**).

| Modelo                  | Accuracy | Precision | Recall | F1-score | ROC AUC |
|--------------------------|----------|-----------|--------|----------|---------|
| **XGBClassifier**        | 0.706    | 0.056     | **0.639** | **0.103**  | **0.731** |
| DecisionTreeClassifier   | 0.696    | 0.053     | 0.624  | 0.098    | 0.712   |
| LogisticRegression       | 0.700    | 0.052     | 0.598  | 0.095    | 0.702   |

### Crit√©rios da escolha
- **Recall**: XGBoost obteve o melhor valor, fundamental para **n√£o deixar de identificar casos graves**.  
- **ROC AUC**: maior separa√ß√£o entre classes, garantindo maior robustez.  
- **F1-score**: tamb√©m superior, mesmo com o desbalanceamento da base.  
- **Conclus√£o**: o modelo final escolhido foi o **XGBoost**, salvo em `models/xgb_model.pkl`. 


> ‚ÑπÔ∏è _Aviso: Este projeto tem fins educacionais e de pesquisa. O modelo n√£o substitui avalia√ß√£o m√©dica._